{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cddf0f9-d074-48ef-a582-33bb08cb0417",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# installing tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f633536-cb03-4eb5-8a40-8985ba04c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\cungv\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "decc08e5-263d-4693-886e-84371f387e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af75986e-7b0a-4823-8f36-6bcf091bd633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "527534d4-aa30-4f85-90d2-02f8c6b46ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = tf.add(a, b)\n",
    "\n",
    "print(c.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea80edbd-71fc-4ae8-ac34-a75694308776",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Downloading spurge nettle pictures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "468df12d-e65b-430f-bc82-e4e619db335d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                  uuid    observed_on_string  \\\n",
      "0  18042  b129acf2-22b7-49f1-a7d8-c9a8888b550e    May 07, 2009 09:21   \n",
      "1  68317  528d10ac-74e1-4045-ac23-4d51802e5d47    May 11, 2011 11:25   \n",
      "2  68318  0b311f52-e245-4997-8b52-4859c70a0101  March 26, 2012 12:16   \n",
      "\n",
      "  observed_on         time_observed_at                   time_zone  user_id  \\\n",
      "0  2009-05-07  2009-05-07 16:21:00 UTC  Pacific Time (US & Canada)      604   \n",
      "1  2011-05-11  2011-05-11 15:25:00 UTC  Eastern Time (US & Canada)     5464   \n",
      "2  2012-03-26  2012-03-26 16:16:00 UTC  Eastern Time (US & Canada)     5464   \n",
      "\n",
      "         user_login  user_name               created_at  ... geoprivacy  \\\n",
      "0         eric_hunt  Eric Hunt  2011-05-24 23:27:18 UTC  ...        NaN   \n",
      "1  guerillafarmer99   SharpJ99  2012-04-21 00:00:23 UTC  ...        NaN   \n",
      "2  guerillafarmer99   SharpJ99  2012-04-21 00:02:59 UTC  ...        NaN   \n",
      "\n",
      "  taxon_geoprivacy coordinates_obscured positioning_method positioning_device  \\\n",
      "0              NaN                False                NaN                NaN   \n",
      "1              NaN                False                NaN                NaN   \n",
      "2              NaN                False                NaN                NaN   \n",
      "\n",
      "   species_guess         scientific_name    common_name  iconic_taxon_name  \\\n",
      "0  Spurge Nettle  Cnidoscolus stimulosus  spurge nettle            Plantae   \n",
      "1  spurge nettle  Cnidoscolus stimulosus  spurge nettle            Plantae   \n",
      "2  spurge nettle  Cnidoscolus stimulosus  spurge nettle            Plantae   \n",
      "\n",
      "   taxon_id  \n",
      "0    160765  \n",
      "1    160765  \n",
      "2    160765  \n",
      "\n",
      "[3 rows x 40 columns]\n",
      "Columns: ['id', 'uuid', 'observed_on_string', 'observed_on', 'time_observed_at', 'time_zone', 'user_id', 'user_login', 'user_name', 'created_at', 'updated_at', 'quality_grade', 'license', 'url', 'image_url', 'sound_url', 'tag_list', 'description', 'num_identification_agreements', 'num_identification_disagreements', 'captive_cultivated', 'oauth_application_id', 'place_guess', 'latitude', 'longitude', 'positional_accuracy', 'private_place_guess', 'private_latitude', 'private_longitude', 'public_positional_accuracy', 'geoprivacy', 'taxon_geoprivacy', 'coordinates_obscured', 'positioning_method', 'positioning_device', 'species_guess', 'scientific_name', 'common_name', 'iconic_taxon_name', 'taxon_id']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://static.inaturalist.org/photos/33268/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/103570/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/103571/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/306003/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://static.inaturalist.org/photos/359120/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images:  96%|██████████████████████████████████████████████████▊  | 11060/11537 [24:17:37<02:30,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for https://inaturalist-open-data.s3.amazonaws.com/photos/523401569/medium.jpg: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images: 100%|█████████████████████████████████████████████████████| 11537/11537 [24:20:44<00:00,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saved images in: inat_images_spurge_nettle. Errors: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  #adds a progress bar \n",
    "from urllib.parse import urlparse #helps extract the file extension (.jpg, .png, etc.) from a URL.\n",
    "from os.path import splitext, basename #separate filename and extension from a URL path.\n",
    "from IPython.display import Image, display #preview images inline.\n",
    "\n",
    "# === 1) Load your CSV (same folder as the notebook) ===\n",
    "CSV_NAME = \"spurge-nettle.csv\"  # <-- change if your filename differs\n",
    "df = pd.read_csv(CSV_NAME)\n",
    "\n",
    "# Quick peek so you can confirm column names\n",
    "print(df.head(3))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# === 2) Pick the image URL column automatically ===\n",
    "# Add/adjust candidates if your CSV uses a different name\n",
    "CANDIDATE_COLS = [\"image_url\", \"photo_url\", \"url\", \"photo\", \"image\"]\n",
    "url_col = next((c for c in CANDIDATE_COLS if c in df.columns), None)\n",
    "if url_col is None:\n",
    "    raise ValueError(\n",
    "        f\"Could not find an image URL column. Look for one like {CANDIDATE_COLS} and set url_col manually.\"\n",
    "    )\n",
    "\n",
    "# Optional: prefer a stable identifier for filenames if present\n",
    "id_col = next((c for c in [\"id\", \"observation_id\", \"photo_id\"] if c in df.columns), None)\n",
    "\n",
    "# Unique, non-null URLs\n",
    "image_urls = df[url_col].dropna().astype(str).unique()\n",
    "\n",
    "# === 3) Where to save ===\n",
    "OUT_DIR = \"inat_images_spurge_nettle\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# === 4) Preview a few images inline (no download yet) ===\n",
    "for url in image_urls[:5]:\n",
    "    try:\n",
    "        display(Image(url=url))\n",
    "    except Exception as e:\n",
    "        print(f\"Preview failed for {url}: {e}\")\n",
    "\n",
    "# === 5) Helper to pick a reasonable filename ===\n",
    "def filename_for(idx, url, row_id=None):\n",
    "    # Try to preserve extension from URL; default to .jpg\n",
    "    path = urlparse(url).path\n",
    "    ext = splitext(path)[1].lower()\n",
    "    if ext not in [\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\"]:\n",
    "        ext = \".jpg\"\n",
    "    # Prefer an ID from the CSV when available\n",
    "    if row_id is not None:\n",
    "        return os.path.join(OUT_DIR, f\"{row_id}{ext}\")\n",
    "    return os.path.join(OUT_DIR, f\"photo_{idx}{ext}\")\n",
    "\n",
    "# Build a fast lookup from URL -> row id (if available)\n",
    "id_by_url = {}\n",
    "if id_col is not None:\n",
    "    # Use first occurrence per URL\n",
    "    first_indices = ~df[url_col].isna()\n",
    "    for _, r in df.loc[first_indices, [url_col, id_col]].dropna(subset=[url_col]).iterrows():\n",
    "        id_by_url.setdefault(str(r[url_col]), r[id_col])\n",
    "\n",
    "# === 6) Download (resumable + polite) ===\n",
    "headers = {\"User-Agent\": \"iNat downloader for research (requests)\"}  # polite header\n",
    "errors = 0\n",
    "\n",
    "for i, url in enumerate(tqdm(image_urls, desc=\"Downloading images\")):\n",
    "    row_id = id_by_url.get(url)\n",
    "    out_path = filename_for(i, url, row_id=row_id)\n",
    "\n",
    "    # Skip files already downloaded\n",
    "    if os.path.exists(out_path):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, timeout=15)\n",
    "        if resp.status_code == 200:\n",
    "            with open(out_path, \"wb\") as f:\n",
    "                f.write(resp.content)\n",
    "        else:\n",
    "            print(f\"Failed {url} (HTTP {resp.status_code})\")\n",
    "            errors += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {url}: {e}\")\n",
    "        errors += 1\n",
    "        time.sleep(1)  # brief pause on error\n",
    "\n",
    "    # Be gentle: tiny pause every 200 downloads\n",
    "    if (i + 1) % 200 == 0:\n",
    "        time.sleep(0.5)\n",
    "\n",
    "print(f\"Done. Saved images in: {OUT_DIR}. Errors: {errors}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa6ab67-cdc3-48c2-9828-48531dcae184",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# installing pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e348f376-04e5-4475-80b8-73e3b4f154dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\cungv\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b05304ea-3f93-451d-9c6f-73594c8bb5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cungv\\anaconda3\\python.exe\n",
      "C:\\Users\\cungv\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n",
      "C:\\Users\\cungv\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!where python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998890af-a836-4466-b4e2-365ff21c1fb7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Downloading Texas Bull Nettle pictures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca5f278-b7fe-49e6-a59a-5edc2c077a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                  uuid  \\\n",
      "0   98836  216cfaf8-b8ac-41a8-b345-ed307645dce7   \n",
      "1  232803  daa6a01f-7dfd-418b-ade7-e0c6bb95929c   \n",
      "2  242021  063d7d74-53d6-4046-90e5-3ac25fed083c   \n",
      "\n",
      "                        observed_on_string observed_on  \\\n",
      "0                      July 04, 2012 18:14  2012-07-04   \n",
      "1  Tue Apr 09 2013 08:14:55 GMT-0500 (CDT)  2013-04-09   \n",
      "2  Sun Apr 21 2013 11:41:17 GMT-0500 (CDT)  2013-04-21   \n",
      "\n",
      "          time_observed_at                   time_zone  user_id  user_login  \\\n",
      "0  2012-07-04 23:14:00 UTC  Central Time (US & Canada)     5429  gaberlunzi   \n",
      "1  2013-04-09 13:14:55 UTC  Central Time (US & Canada)     9685     mikaelb   \n",
      "2  2013-04-21 16:41:17 UTC  Central Time (US & Canada)     9685     mikaelb   \n",
      "\n",
      "        user_name               created_at  ... geoprivacy taxon_geoprivacy  \\\n",
      "0             NaN  2012-07-05 14:30:26 UTC  ...        NaN              NaN   \n",
      "1  Mikael Behrens  2013-04-09 15:04:35 UTC  ...        NaN              NaN   \n",
      "2  Mikael Behrens  2013-04-21 17:56:27 UTC  ...        NaN              NaN   \n",
      "\n",
      "  coordinates_obscured positioning_method positioning_device  \\\n",
      "0                False                NaN                NaN   \n",
      "1                False                NaN                NaN   \n",
      "2                False                NaN                NaN   \n",
      "\n",
      "       species_guess      scientific_name        common_name  \\\n",
      "0  Texas Bull Nettle  Cnidoscolus texanus  Texas Bull Nettle   \n",
      "1  Texas Bull Nettle  Cnidoscolus texanus  Texas Bull Nettle   \n",
      "2  Texas Bull Nettle  Cnidoscolus texanus  Texas Bull Nettle   \n",
      "\n",
      "   iconic_taxon_name  taxon_id  \n",
      "0            Plantae    133074  \n",
      "1            Plantae    133074  \n",
      "2            Plantae    133074  \n",
      "\n",
      "[3 rows x 40 columns]\n",
      "Columns: ['id', 'uuid', 'observed_on_string', 'observed_on', 'time_observed_at', 'time_zone', 'user_id', 'user_login', 'user_name', 'created_at', 'updated_at', 'quality_grade', 'license', 'url', 'image_url', 'sound_url', 'tag_list', 'description', 'num_identification_agreements', 'num_identification_disagreements', 'captive_cultivated', 'oauth_application_id', 'place_guess', 'latitude', 'longitude', 'positional_accuracy', 'private_place_guess', 'private_latitude', 'private_longitude', 'public_positional_accuracy', 'geoprivacy', 'taxon_geoprivacy', 'coordinates_obscured', 'positioning_method', 'positioning_device', 'species_guess', 'scientific_name', 'common_name', 'iconic_taxon_name', 'taxon_id']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/143361/medium.JPG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/292782/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/302726/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/309149/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/330408/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images: 100%|██████████████████████████████████████████████████████| 10006/10006 [2:20:33<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saved images in: inat_images_texas_bull_nettle. Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urlparse\n",
    "from os.path import splitext\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# === 1) Load your CSV (make sure it's in the same folder as the notebook) ===\n",
    "CSV_NAME = \"texas-bull-nettle.csv\"\n",
    "df = pd.read_csv(CSV_NAME)\n",
    "\n",
    "# Peek at the data\n",
    "print(df.head(3))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# === 2) Find the URL column automatically ===\n",
    "CANDIDATE_COLS = [\"image_url\", \"photo_url\", \"url\", \"photo\", \"image\"]\n",
    "url_col = next((c for c in CANDIDATE_COLS if c in df.columns), None)\n",
    "if url_col is None:\n",
    "    raise ValueError(f\"No URL column found. Check columns: {list(df.columns)}\")\n",
    "\n",
    "# Optional: use an ID for filenames if available\n",
    "id_col = next((c for c in [\"id\", \"observation_id\", \"photo_id\"] if c in df.columns), None)\n",
    "\n",
    "# Unique, cleaned URLs\n",
    "image_urls = df[url_col].dropna().astype(str).unique()\n",
    "\n",
    "# === 3) Folder to save images ===\n",
    "OUT_DIR = \"inat_images_texas_bull_nettle\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# === 4) Preview a few images in Jupyter ===\n",
    "for url in image_urls[:5]:\n",
    "    try:\n",
    "        display(Image(url=url))\n",
    "    except Exception as e:\n",
    "        print(f\"Preview failed for {url}: {e}\")\n",
    "\n",
    "# === 5) Filename helper ===\n",
    "def filename_for(idx, url, row_id=None):\n",
    "    path = urlparse(url).path\n",
    "    ext = splitext(path)[1].lower()\n",
    "    if ext not in [\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\"]:\n",
    "        ext = \".jpg\"\n",
    "    if row_id is not None:\n",
    "        return os.path.join(OUT_DIR, f\"{row_id}{ext}\")\n",
    "    return os.path.join(OUT_DIR, f\"photo_{idx}{ext}\")\n",
    "\n",
    "# Map URL → ID (if available)\n",
    "id_by_url = {}\n",
    "if id_col is not None:\n",
    "    for _, r in df[[url_col, id_col]].dropna(subset=[url_col]).iterrows():\n",
    "        u = str(r[url_col])\n",
    "        if u not in id_by_url:\n",
    "            id_by_url[u] = r[id_col]\n",
    "\n",
    "# === 6) Download with retry + polite pause ===\n",
    "headers = {\"User-Agent\": \"iNat downloader for research\"}\n",
    "errors = 0\n",
    "\n",
    "for i, url in enumerate(tqdm(image_urls, desc=\"Downloading images\")):\n",
    "    row_id = id_by_url.get(url)\n",
    "    out_path = filename_for(i, url, row_id=row_id)\n",
    "\n",
    "    if os.path.exists(out_path):\n",
    "        continue  # skip already downloaded\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, timeout=15)\n",
    "        if resp.status_code == 200:\n",
    "            with open(out_path, \"wb\") as f:\n",
    "                f.write(resp.content)\n",
    "        else:\n",
    "            print(f\"Failed {url} (HTTP {resp.status_code})\")\n",
    "            errors += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {url}: {e}\")\n",
    "        errors += 1\n",
    "        time.sleep(1)\n",
    "\n",
    "    if (i + 1) % 200 == 0:\n",
    "        time.sleep(0.5)\n",
    "\n",
    "print(f\"Done. Saved images in: {OUT_DIR}. Errors: {errors}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2396f5ec-3e25-4f72-9f57-a4a99a47162b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# checks how many pictures downloaded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f55e84-3568-4fb6-be10-3c638808ed25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== spurge-nettle.csv → inat_images_spurge_nettle ===\n",
      "URL column:              image_url\n",
      "Expected (unique URLs):  11537\n",
      "Downloaded (files):      11530\n",
      "Missing files:           7\n",
      "Tiny/suspicious files:   0\n",
      "\n",
      "=== texas-bull-nettle.csv → inat_images_texas_bull_nettle ===\n",
      "URL column:              image_url\n",
      "Expected (unique URLs):  10006\n",
      "Downloaded (files):      10006\n",
      "Counts match ✔\n",
      "Tiny/suspicious files:   0\n",
      "\n",
      "No tiny files detected in inat_images_spurge_nettle.\n",
      "No tiny files detected in inat_images_texas_bull_nettle.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ---- CONFIG: names & folders ----\n",
    "DATA = [\n",
    "    (\"spurge-nettle.csv\",        \"inat_images_spurge_nettle\"),\n",
    "    (\"texas-bull-nettle.csv\",    \"inat_images_texas_bull_nettle\"),\n",
    "]\n",
    "\n",
    "CANDIDATE_URL_COLS = [\"image_url\", \"photo_url\", \"url\", \"photo\", \"image\"]\n",
    "MIN_BYTES_TINY = 1024  # under 1KB likely broken\n",
    "\n",
    "def find_url_col(df):\n",
    "    for c in CANDIDATE_URL_COLS:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise ValueError(f\"Could not find a URL column. Available columns: {list(df.columns)}\")\n",
    "\n",
    "def count_files(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        return 0\n",
    "    return sum(\n",
    "        1 for f in os.listdir(folder)\n",
    "        if os.path.isfile(os.path.join(folder, f))\n",
    "    )\n",
    "\n",
    "def tiny_files(folder, min_bytes=MIN_BYTES_TINY):\n",
    "    if not os.path.exists(folder):\n",
    "        return []\n",
    "    tiny = []\n",
    "    for f in os.listdir(folder):\n",
    "        p = os.path.join(folder, f)\n",
    "        if os.path.isfile(p):\n",
    "            try:\n",
    "                if os.path.getsize(p) < min_bytes:\n",
    "                    tiny.append(f)\n",
    "            except OSError:\n",
    "                tiny.append(f\"[stat_error]{f}\")\n",
    "    return tiny\n",
    "\n",
    "summary = []\n",
    "\n",
    "for csv_name, folder in DATA:\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_name)\n",
    "    url_col = find_url_col(df)\n",
    "\n",
    "    # Expected = unique, non-null URLs\n",
    "    urls = df[url_col].dropna().astype(str).unique()\n",
    "    expected = len(urls)\n",
    "\n",
    "    # Downloaded = number of files present\n",
    "    downloaded = count_files(folder)\n",
    "\n",
    "    # Suspicious tiny files\n",
    "    tiny = tiny_files(folder)\n",
    "    tiny_count = len(tiny)\n",
    "\n",
    "    # Quick status\n",
    "    summary.append({\n",
    "        \"csv\": csv_name,\n",
    "        \"folder\": folder,\n",
    "        \"url_column\": url_col,\n",
    "        \"expected_unique_urls\": expected,\n",
    "        \"downloaded_files\": downloaded,\n",
    "        \"missing_or_extra\": expected - downloaded,  # positive => missing; negative => extras in folder\n",
    "        \"tiny_suspicious_files\": tiny_count\n",
    "    })\n",
    "\n",
    "# Print the summary\n",
    "for s in summary:\n",
    "    print(f\"=== {s['csv']} → {s['folder']} ===\")\n",
    "    print(f\"URL column:              {s['url_column']}\")\n",
    "    print(f\"Expected (unique URLs):  {s['expected_unique_urls']}\")\n",
    "    print(f\"Downloaded (files):      {s['downloaded_files']}\")\n",
    "    miss_extra = s['missing_or_extra']\n",
    "    if miss_extra > 0:\n",
    "        print(f\"Missing files:           {miss_extra}\")\n",
    "    elif miss_extra < 0:\n",
    "        print(f\"Extra files in folder:   {-miss_extra}\")\n",
    "    else:\n",
    "        print(\"Counts match ✔\")\n",
    "    print(f\"Tiny/suspicious files:   {s['tiny_suspicious_files']}\")\n",
    "    print()\n",
    "\n",
    "# (Optional) show a few examples of tiny files for the first dataset if any\n",
    "for csv_name, folder in DATA:\n",
    "    t = tiny_files(folder)\n",
    "    if t:\n",
    "        print(f\"Examples of tiny files in {folder}: {t[:10]}\")\n",
    "    else:\n",
    "        print(f\"No tiny files detected in {folder}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8978c10c-e563-40d9-a61e-0289b729a38f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Downloading important files for image segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e0b732-152a-493c-b0b1-359b71e5f6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tensorflow/examples.git\n",
      "  Cloning https://github.com/tensorflow/examples.git to c:\\users\\cungv\\appdata\\local\\temp\\pip-req-build-wi8s03ht\n",
      "  Resolved https://github.com/tensorflow/examples.git to commit c82672b5a69916f22b0dd380481e000142c746d5\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: absl-py in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow-examples==0.1755771098.1142655575095463436003189777410900689228873025237) (2.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow-examples==0.1755771098.1142655575095463436003189777410900689228873025237) (1.17.0)\n",
      "Building wheels for collected packages: tensorflow-examples\n",
      "  Building wheel for tensorflow-examples (setup.py): started\n",
      "  Building wheel for tensorflow-examples (setup.py): finished with status 'done'\n",
      "  Created wheel for tensorflow-examples: filename=tensorflow_examples-0.1755771098.1142655575095463436003189777410900689228873025237-py3-none-any.whl size=303881 sha256=8452c142e70c32834df254fb97519e273380f0d52daba6068d6278afb20161d3\n",
      "  Stored in directory: C:\\Users\\cungv\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-gvk7s0pc\\wheels\\1e\\48\\10\\2e02193b6978d95aabf71261ad166a2aa717af9cef5e975825\n",
      "Successfully built tensorflow-examples\n",
      "Installing collected packages: tensorflow-examples\n",
      "Successfully installed tensorflow-examples-0.1755771098.1142655575095463436003189777410900689228873025237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/examples.git 'C:\\Users\\cungv\\AppData\\Local\\Temp\\pip-req-build-wi8s03ht'\n",
      "  DEPRECATION: Building 'tensorflow-examples' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'tensorflow-examples'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\cungv\\anaconda3\\lib\\site-packages (3.11.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from keras) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from keras) (2.1.3)\n",
      "Requirement already satisfied: rich in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from keras) (0.17.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from keras) (0.5.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from keras) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'promise' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'promise'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "ERROR: Could not find a version that satisfies the requirement tensorflow-text (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow-text\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/tensorflow/examples.git\n",
    "!pip install -U keras\n",
    "!pip install -q tensorflow_datasets\n",
    "!pip install -q -U tensorflow-text tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c794d7a-5af0-4d2b-8e0a-4f03e2155198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab932b3-9cd7-4706-8672-89047f2158f2",
   "metadata": {},
   "source": [
    "# Normalizing and loading image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f64c206-923c-4d93-8b7b-90e1b6951ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = (128, 128)\n",
    "\n",
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_mask = tf.cast(input_mask > 127, tf.float32)  # convert 0/255 → 0/1\n",
    "    return input_image, input_mask\n",
    "\n",
    "def load_image(img_path, mask_path):\n",
    "    # Read and decode the image\n",
    "    input_image = tf.io.read_file(img_path)\n",
    "    input_image = tf.image.decode_jpeg(input_image, channels=3)\n",
    "    input_image = tf.image.resize(input_image, IMG_SIZE)\n",
    "\n",
    "    # Read and decode the mask\n",
    "    input_mask = tf.io.read_file(mask_path)\n",
    "    input_mask = tf.image.decode_png(input_mask, channels=1)\n",
    "    input_mask = tf.image.resize(input_mask, IMG_SIZE, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # Normalize both\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "    return input_image, input_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f1715c-515e-4f50-9848-b62050e0a12d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
