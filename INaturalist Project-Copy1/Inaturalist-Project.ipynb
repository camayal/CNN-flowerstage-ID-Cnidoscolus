{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2dab2b3-751a-4ff8-a348-6f73e47c6081",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# installing tensorflow and sorting images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f633536-cb03-4eb5-8a40-8985ba04c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\cungv\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "decc08e5-263d-4693-886e-84371f387e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af75986e-7b0a-4823-8f36-6bcf091bd633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "527534d4-aa30-4f85-90d2-02f8c6b46ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = tf.add(a, b)\n",
    "\n",
    "print(c.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "468df12d-e65b-430f-bc82-e4e619db335d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                  uuid    observed_on_string  \\\n",
      "0  18042  b129acf2-22b7-49f1-a7d8-c9a8888b550e    May 07, 2009 09:21   \n",
      "1  68317  528d10ac-74e1-4045-ac23-4d51802e5d47    May 11, 2011 11:25   \n",
      "2  68318  0b311f52-e245-4997-8b52-4859c70a0101  March 26, 2012 12:16   \n",
      "\n",
      "  observed_on         time_observed_at                   time_zone  user_id  \\\n",
      "0  2009-05-07  2009-05-07 16:21:00 UTC  Pacific Time (US & Canada)      604   \n",
      "1  2011-05-11  2011-05-11 15:25:00 UTC  Eastern Time (US & Canada)     5464   \n",
      "2  2012-03-26  2012-03-26 16:16:00 UTC  Eastern Time (US & Canada)     5464   \n",
      "\n",
      "         user_login  user_name               created_at  ... geoprivacy  \\\n",
      "0         eric_hunt  Eric Hunt  2011-05-24 23:27:18 UTC  ...        NaN   \n",
      "1  guerillafarmer99   SharpJ99  2012-04-21 00:00:23 UTC  ...        NaN   \n",
      "2  guerillafarmer99   SharpJ99  2012-04-21 00:02:59 UTC  ...        NaN   \n",
      "\n",
      "  taxon_geoprivacy coordinates_obscured positioning_method positioning_device  \\\n",
      "0              NaN                False                NaN                NaN   \n",
      "1              NaN                False                NaN                NaN   \n",
      "2              NaN                False                NaN                NaN   \n",
      "\n",
      "   species_guess         scientific_name    common_name  iconic_taxon_name  \\\n",
      "0  Spurge Nettle  Cnidoscolus stimulosus  spurge nettle            Plantae   \n",
      "1  spurge nettle  Cnidoscolus stimulosus  spurge nettle            Plantae   \n",
      "2  spurge nettle  Cnidoscolus stimulosus  spurge nettle            Plantae   \n",
      "\n",
      "   taxon_id  \n",
      "0    160765  \n",
      "1    160765  \n",
      "2    160765  \n",
      "\n",
      "[3 rows x 40 columns]\n",
      "Columns: ['id', 'uuid', 'observed_on_string', 'observed_on', 'time_observed_at', 'time_zone', 'user_id', 'user_login', 'user_name', 'created_at', 'updated_at', 'quality_grade', 'license', 'url', 'image_url', 'sound_url', 'tag_list', 'description', 'num_identification_agreements', 'num_identification_disagreements', 'captive_cultivated', 'oauth_application_id', 'place_guess', 'latitude', 'longitude', 'positional_accuracy', 'private_place_guess', 'private_latitude', 'private_longitude', 'public_positional_accuracy', 'geoprivacy', 'taxon_geoprivacy', 'coordinates_obscured', 'positioning_method', 'positioning_device', 'species_guess', 'scientific_name', 'common_name', 'iconic_taxon_name', 'taxon_id']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://static.inaturalist.org/photos/33268/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/103570/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/103571/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/306003/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://static.inaturalist.org/photos/359120/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 11060/11537 [24:17:37<02:30,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for https://inaturalist-open-data.s3.amazonaws.com/photos/523401569/medium.jpg: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11537/11537 [24:20:44<00:00,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saved images in: inat_images_spurge_nettle. Errors: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  #adds a progress bar \n",
    "from urllib.parse import urlparse #helps extract the file extension (.jpg, .png, etc.) from a URL.\n",
    "from os.path import splitext, basename #separate filename and extension from a URL path.\n",
    "from IPython.display import Image, display #preview images inline.\n",
    "\n",
    "# === 1) Load your CSV (same folder as the notebook) ===\n",
    "CSV_NAME = \"spurge-nettle.csv\"  # <-- change if your filename differs\n",
    "df = pd.read_csv(CSV_NAME)\n",
    "\n",
    "# Quick peek so you can confirm column names\n",
    "print(df.head(3))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# === 2) Pick the image URL column automatically ===\n",
    "# Add/adjust candidates if your CSV uses a different name\n",
    "CANDIDATE_COLS = [\"image_url\", \"photo_url\", \"url\", \"photo\", \"image\"]\n",
    "url_col = next((c for c in CANDIDATE_COLS if c in df.columns), None)\n",
    "if url_col is None:\n",
    "    raise ValueError(\n",
    "        f\"Could not find an image URL column. Look for one like {CANDIDATE_COLS} and set url_col manually.\"\n",
    "    )\n",
    "\n",
    "# Optional: prefer a stable identifier for filenames if present\n",
    "id_col = next((c for c in [\"id\", \"observation_id\", \"photo_id\"] if c in df.columns), None)\n",
    "\n",
    "# Unique, non-null URLs\n",
    "image_urls = df[url_col].dropna().astype(str).unique()\n",
    "\n",
    "# === 3) Where to save ===\n",
    "OUT_DIR = \"inat_images_spurge_nettle\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# === 4) Preview a few images inline (no download yet) ===\n",
    "for url in image_urls[:5]:\n",
    "    try:\n",
    "        display(Image(url=url))\n",
    "    except Exception as e:\n",
    "        print(f\"Preview failed for {url}: {e}\")\n",
    "\n",
    "# === 5) Helper to pick a reasonable filename ===\n",
    "def filename_for(idx, url, row_id=None):\n",
    "    # Try to preserve extension from URL; default to .jpg\n",
    "    path = urlparse(url).path\n",
    "    ext = splitext(path)[1].lower()\n",
    "    if ext not in [\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\"]:\n",
    "        ext = \".jpg\"\n",
    "    # Prefer an ID from the CSV when available\n",
    "    if row_id is not None:\n",
    "        return os.path.join(OUT_DIR, f\"{row_id}{ext}\")\n",
    "    return os.path.join(OUT_DIR, f\"photo_{idx}{ext}\")\n",
    "\n",
    "# Build a fast lookup from URL -> row id (if available)\n",
    "id_by_url = {}\n",
    "if id_col is not None:\n",
    "    # Use first occurrence per URL\n",
    "    first_indices = ~df[url_col].isna()\n",
    "    for _, r in df.loc[first_indices, [url_col, id_col]].dropna(subset=[url_col]).iterrows():\n",
    "        id_by_url.setdefault(str(r[url_col]), r[id_col])\n",
    "\n",
    "# === 6) Download (resumable + polite) ===\n",
    "headers = {\"User-Agent\": \"iNat downloader for research (requests)\"}  # polite header\n",
    "errors = 0\n",
    "\n",
    "for i, url in enumerate(tqdm(image_urls, desc=\"Downloading images\")):\n",
    "    row_id = id_by_url.get(url)\n",
    "    out_path = filename_for(i, url, row_id=row_id)\n",
    "\n",
    "    # Skip files already downloaded\n",
    "    if os.path.exists(out_path):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, timeout=15)\n",
    "        if resp.status_code == 200:\n",
    "            with open(out_path, \"wb\") as f:\n",
    "                f.write(resp.content)\n",
    "        else:\n",
    "            print(f\"Failed {url} (HTTP {resp.status_code})\")\n",
    "            errors += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {url}: {e}\")\n",
    "        errors += 1\n",
    "        time.sleep(1)  # brief pause on error\n",
    "\n",
    "    # Be gentle: tiny pause every 200 downloads\n",
    "    if (i + 1) % 200 == 0:\n",
    "        time.sleep(0.5)\n",
    "\n",
    "print(f\"Done. Saved images in: {OUT_DIR}. Errors: {errors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e348f376-04e5-4475-80b8-73e3b4f154dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\cungv\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b05304ea-3f93-451d-9c6f-73594c8bb5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cungv\\anaconda3\\python.exe\n",
      "C:\\Users\\cungv\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n",
      "C:\\Users\\cungv\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca5f278-b7fe-49e6-a59a-5edc2c077a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                  uuid  \\\n",
      "0   98836  216cfaf8-b8ac-41a8-b345-ed307645dce7   \n",
      "1  232803  daa6a01f-7dfd-418b-ade7-e0c6bb95929c   \n",
      "2  242021  063d7d74-53d6-4046-90e5-3ac25fed083c   \n",
      "\n",
      "                        observed_on_string observed_on  \\\n",
      "0                      July 04, 2012 18:14  2012-07-04   \n",
      "1  Tue Apr 09 2013 08:14:55 GMT-0500 (CDT)  2013-04-09   \n",
      "2  Sun Apr 21 2013 11:41:17 GMT-0500 (CDT)  2013-04-21   \n",
      "\n",
      "          time_observed_at                   time_zone  user_id  user_login  \\\n",
      "0  2012-07-04 23:14:00 UTC  Central Time (US & Canada)     5429  gaberlunzi   \n",
      "1  2013-04-09 13:14:55 UTC  Central Time (US & Canada)     9685     mikaelb   \n",
      "2  2013-04-21 16:41:17 UTC  Central Time (US & Canada)     9685     mikaelb   \n",
      "\n",
      "        user_name               created_at  ... geoprivacy taxon_geoprivacy  \\\n",
      "0             NaN  2012-07-05 14:30:26 UTC  ...        NaN              NaN   \n",
      "1  Mikael Behrens  2013-04-09 15:04:35 UTC  ...        NaN              NaN   \n",
      "2  Mikael Behrens  2013-04-21 17:56:27 UTC  ...        NaN              NaN   \n",
      "\n",
      "  coordinates_obscured positioning_method positioning_device  \\\n",
      "0                False                NaN                NaN   \n",
      "1                False                NaN                NaN   \n",
      "2                False                NaN                NaN   \n",
      "\n",
      "       species_guess      scientific_name        common_name  \\\n",
      "0  Texas Bull Nettle  Cnidoscolus texanus  Texas Bull Nettle   \n",
      "1  Texas Bull Nettle  Cnidoscolus texanus  Texas Bull Nettle   \n",
      "2  Texas Bull Nettle  Cnidoscolus texanus  Texas Bull Nettle   \n",
      "\n",
      "   iconic_taxon_name  taxon_id  \n",
      "0            Plantae    133074  \n",
      "1            Plantae    133074  \n",
      "2            Plantae    133074  \n",
      "\n",
      "[3 rows x 40 columns]\n",
      "Columns: ['id', 'uuid', 'observed_on_string', 'observed_on', 'time_observed_at', 'time_zone', 'user_id', 'user_login', 'user_name', 'created_at', 'updated_at', 'quality_grade', 'license', 'url', 'image_url', 'sound_url', 'tag_list', 'description', 'num_identification_agreements', 'num_identification_disagreements', 'captive_cultivated', 'oauth_application_id', 'place_guess', 'latitude', 'longitude', 'positional_accuracy', 'private_place_guess', 'private_latitude', 'private_longitude', 'public_positional_accuracy', 'geoprivacy', 'taxon_geoprivacy', 'coordinates_obscured', 'positioning_method', 'positioning_device', 'species_guess', 'scientific_name', 'common_name', 'iconic_taxon_name', 'taxon_id']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/143361/medium.JPG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/292782/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/302726/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/309149/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://inaturalist-open-data.s3.amazonaws.com/photos/330408/medium.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10006/10006 [2:20:33<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saved images in: inat_images_texas_bull_nettle. Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urlparse\n",
    "from os.path import splitext\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# === 1) Load your CSV (make sure it's in the same folder as the notebook) ===\n",
    "CSV_NAME = \"texas-bull-nettle.csv\"\n",
    "df = pd.read_csv(CSV_NAME)\n",
    "\n",
    "# Peek at the data\n",
    "print(df.head(3))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# === 2) Find the URL column automatically ===\n",
    "CANDIDATE_COLS = [\"image_url\", \"photo_url\", \"url\", \"photo\", \"image\"]\n",
    "url_col = next((c for c in CANDIDATE_COLS if c in df.columns), None)\n",
    "if url_col is None:\n",
    "    raise ValueError(f\"No URL column found. Check columns: {list(df.columns)}\")\n",
    "\n",
    "# Optional: use an ID for filenames if available\n",
    "id_col = next((c for c in [\"id\", \"observation_id\", \"photo_id\"] if c in df.columns), None)\n",
    "\n",
    "# Unique, cleaned URLs\n",
    "image_urls = df[url_col].dropna().astype(str).unique()\n",
    "\n",
    "# === 3) Folder to save images ===\n",
    "OUT_DIR = \"inat_images_texas_bull_nettle\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# === 4) Preview a few images in Jupyter ===\n",
    "for url in image_urls[:5]:\n",
    "    try:\n",
    "        display(Image(url=url))\n",
    "    except Exception as e:\n",
    "        print(f\"Preview failed for {url}: {e}\")\n",
    "\n",
    "# === 5) Filename helper ===\n",
    "def filename_for(idx, url, row_id=None):\n",
    "    path = urlparse(url).path\n",
    "    ext = splitext(path)[1].lower()\n",
    "    if ext not in [\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\"]:\n",
    "        ext = \".jpg\"\n",
    "    if row_id is not None:\n",
    "        return os.path.join(OUT_DIR, f\"{row_id}{ext}\")\n",
    "    return os.path.join(OUT_DIR, f\"photo_{idx}{ext}\")\n",
    "\n",
    "# Map URL â†’ ID (if available)\n",
    "id_by_url = {}\n",
    "if id_col is not None:\n",
    "    for _, r in df[[url_col, id_col]].dropna(subset=[url_col]).iterrows():\n",
    "        u = str(r[url_col])\n",
    "        if u not in id_by_url:\n",
    "            id_by_url[u] = r[id_col]\n",
    "\n",
    "# === 6) Download with retry + polite pause ===\n",
    "headers = {\"User-Agent\": \"iNat downloader for research\"}\n",
    "errors = 0\n",
    "\n",
    "for i, url in enumerate(tqdm(image_urls, desc=\"Downloading images\")):\n",
    "    row_id = id_by_url.get(url)\n",
    "    out_path = filename_for(i, url, row_id=row_id)\n",
    "\n",
    "    if os.path.exists(out_path):\n",
    "        continue  # skip already downloaded\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, timeout=15)\n",
    "        if resp.status_code == 200:\n",
    "            with open(out_path, \"wb\") as f:\n",
    "                f.write(resp.content)\n",
    "        else:\n",
    "            print(f\"Failed {url} (HTTP {resp.status_code})\")\n",
    "            errors += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {url}: {e}\")\n",
    "        errors += 1\n",
    "        time.sleep(1)\n",
    "\n",
    "    if (i + 1) % 200 == 0:\n",
    "        time.sleep(0.5)\n",
    "\n",
    "print(f\"Done. Saved images in: {OUT_DIR}. Errors: {errors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f55e84-3568-4fb6-be10-3c638808ed25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== spurge-nettle.csv â†’ inat_images_spurge_nettle ===\n",
      "URL column:              image_url\n",
      "Expected (unique URLs):  11537\n",
      "Downloaded (files):      11530\n",
      "Missing files:           7\n",
      "Tiny/suspicious files:   0\n",
      "\n",
      "=== texas-bull-nettle.csv â†’ inat_images_texas_bull_nettle ===\n",
      "URL column:              image_url\n",
      "Expected (unique URLs):  10006\n",
      "Downloaded (files):      10006\n",
      "Counts match âœ”\n",
      "Tiny/suspicious files:   0\n",
      "\n",
      "No tiny files detected in inat_images_spurge_nettle.\n",
      "No tiny files detected in inat_images_texas_bull_nettle.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ---- CONFIG: names & folders ----\n",
    "DATA = [\n",
    "    (\"spurge-nettle.csv\",        \"inat_images_spurge_nettle\"),\n",
    "    (\"texas-bull-nettle.csv\",    \"inat_images_texas_bull_nettle\"),\n",
    "]\n",
    "\n",
    "CANDIDATE_URL_COLS = [\"image_url\", \"photo_url\", \"url\", \"photo\", \"image\"]\n",
    "MIN_BYTES_TINY = 1024  # under 1KB likely broken\n",
    "\n",
    "def find_url_col(df):\n",
    "    for c in CANDIDATE_URL_COLS:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise ValueError(f\"Could not find a URL column. Available columns: {list(df.columns)}\")\n",
    "\n",
    "def count_files(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        return 0\n",
    "    return sum(\n",
    "        1 for f in os.listdir(folder)\n",
    "        if os.path.isfile(os.path.join(folder, f))\n",
    "    )\n",
    "\n",
    "def tiny_files(folder, min_bytes=MIN_BYTES_TINY):\n",
    "    if not os.path.exists(folder):\n",
    "        return []\n",
    "    tiny = []\n",
    "    for f in os.listdir(folder):\n",
    "        p = os.path.join(folder, f)\n",
    "        if os.path.isfile(p):\n",
    "            try:\n",
    "                if os.path.getsize(p) < min_bytes:\n",
    "                    tiny.append(f)\n",
    "            except OSError:\n",
    "                tiny.append(f\"[stat_error]{f}\")\n",
    "    return tiny\n",
    "\n",
    "summary = []\n",
    "\n",
    "for csv_name, folder in DATA:\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_name)\n",
    "    url_col = find_url_col(df)\n",
    "\n",
    "    # Expected = unique, non-null URLs\n",
    "    urls = df[url_col].dropna().astype(str).unique()\n",
    "    expected = len(urls)\n",
    "\n",
    "    # Downloaded = number of files present\n",
    "    downloaded = count_files(folder)\n",
    "\n",
    "    # Suspicious tiny files\n",
    "    tiny = tiny_files(folder)\n",
    "    tiny_count = len(tiny)\n",
    "\n",
    "    # Quick status\n",
    "    summary.append({\n",
    "        \"csv\": csv_name,\n",
    "        \"folder\": folder,\n",
    "        \"url_column\": url_col,\n",
    "        \"expected_unique_urls\": expected,\n",
    "        \"downloaded_files\": downloaded,\n",
    "        \"missing_or_extra\": expected - downloaded,  # positive => missing; negative => extras in folder\n",
    "        \"tiny_suspicious_files\": tiny_count\n",
    "    })\n",
    "\n",
    "# Print the summary\n",
    "for s in summary:\n",
    "    print(f\"=== {s['csv']} â†’ {s['folder']} ===\")\n",
    "    print(f\"URL column:              {s['url_column']}\")\n",
    "    print(f\"Expected (unique URLs):  {s['expected_unique_urls']}\")\n",
    "    print(f\"Downloaded (files):      {s['downloaded_files']}\")\n",
    "    miss_extra = s['missing_or_extra']\n",
    "    if miss_extra > 0:\n",
    "        print(f\"Missing files:           {miss_extra}\")\n",
    "    elif miss_extra < 0:\n",
    "        print(f\"Extra files in folder:   {-miss_extra}\")\n",
    "    else:\n",
    "        print(\"Counts match âœ”\")\n",
    "    print(f\"Tiny/suspicious files:   {s['tiny_suspicious_files']}\")\n",
    "    print()\n",
    "\n",
    "# (Optional) show a few examples of tiny files for the first dataset if any\n",
    "for csv_name, folder in DATA:\n",
    "    t = tiny_files(folder)\n",
    "    if t:\n",
    "        print(f\"Examples of tiny files in {folder}: {t[:10]}\")\n",
    "    else:\n",
    "        print(f\"No tiny files detected in {folder}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23a2111-5230-4819-ac0c-ef3b3693fc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\cungv\\anaconda3\\lib\\site-packages (from opencv-python) (2.1.3)\n",
      "Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "   ---------------------------------------- 0.0/39.0 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 4.2/39.0 MB 24.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 12.8/39.0 MB 31.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 20.2/39.0 MB 35.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 29.4/39.0 MB 34.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.2/39.0 MB 34.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/39.0 MB 35.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.0/39.0 MB 29.3 MB/s  0:00:01\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.12.0.88\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88482338-fd49-419f-8c57-f584f3f4330b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17566b6f-d096-4a17-9e83-678a9fabc072",
   "metadata": {},
   "source": [
    "# labeling flowering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156dabd1-a2d0-4406-9e21-63dfbabf4191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a73026d7c1462894ad5786cd3119bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description=' Back', style=ButtonStyle()), Button(description=' Skip', style=ButtonStyleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05482fdef8634bdea286f8fda1c1287b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cc3614f56a43d3b393a3170240cb2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %pip install ipywidgets   # â† run once if needed, then restart the kernel\n",
    "\n",
    "import os, glob, shutil\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----- CONFIG -----\n",
    "SOURCE = \"random_1000_flowers\"     # folder with unsorted images\n",
    "OUTROOT = \"1000_labeled_flowers\"   # destination root\n",
    "FLOWER_DIR = os.path.join(OUTROOT, \"flower\")\n",
    "NON_DIR    = os.path.join(OUTROOT, \"non_flower\")\n",
    "\n",
    "os.makedirs(FLOWER_DIR, exist_ok=True)\n",
    "os.makedirs(NON_DIR, exist_ok=True)\n",
    "\n",
    "# Collect remaining images to label (skip hidden + non-images)\n",
    "queue = [p for p in glob.glob(os.path.join(SOURCE, \"*\"))\n",
    "         if p.lower().endswith((\".jpg\",\".jpeg\",\".png\")) and os.path.isfile(p)]\n",
    "idx = 0\n",
    "\n",
    "# Widgets\n",
    "img_out = widgets.Output()\n",
    "status  = widgets.HTML()\n",
    "btn_flower = widgets.Button(description=\" Flower\", button_style=\"success\")\n",
    "btn_non    = widgets.Button(description=\" Non-Flower\", button_style=\"danger\")\n",
    "btn_skip   = widgets.Button(description=\" Skip\")\n",
    "btn_back   = widgets.Button(description=\" Back\")\n",
    "\n",
    "def show():\n",
    "    img_out.clear_output(wait=True)\n",
    "    remaining = len(queue) - idx\n",
    "    f_count = len([f for f in os.listdir(FLOWER_DIR) if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
    "    n_count = len([f for f in os.listdir(NON_DIR) if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
    "    if idx >= len(queue):\n",
    "        status.value = f\"âœ… Done. Counts â€” flower: {f_count}, non_flower: {n_count}\"\n",
    "        with img_out: print(\"No more images to label.\")\n",
    "        return\n",
    "    path = queue[idx]\n",
    "    status.value = f\"{idx+1}/{len(queue)}  |  remaining: {remaining}  |  flower: {f_count}  non_flower: {n_count}\"\n",
    "    with img_out:\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(6,6))\n",
    "        try:\n",
    "            im = Image.open(path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Unable to open {os.path.basename(path)}: {e}\")\n",
    "            return\n",
    "        plt.imshow(im); plt.axis(\"off\")\n",
    "        plt.title(os.path.basename(path))\n",
    "        plt.show()\n",
    "\n",
    "def unique_dest(dst_dir, src_path):\n",
    "    base = os.path.join(dst_dir, os.path.basename(src_path))\n",
    "    root, ext = os.path.splitext(base)\n",
    "    k, dst = 1, base\n",
    "    while os.path.exists(dst):\n",
    "        dst = f\"{root}__{k}{ext}\"\n",
    "        k += 1\n",
    "    return dst\n",
    "\n",
    "def move_to(dst_dir):\n",
    "    global idx\n",
    "    if idx >= len(queue): return\n",
    "    src = queue[idx]\n",
    "    dst = unique_dest(dst_dir, src)\n",
    "    shutil.move(src, dst)\n",
    "    idx += 1\n",
    "    show()\n",
    "\n",
    "def skip(_):\n",
    "    global idx\n",
    "    # push current item to end of queue\n",
    "    if idx < len(queue):\n",
    "        queue.append(queue.pop(idx))\n",
    "    show()\n",
    "\n",
    "def back(_):\n",
    "    global idx\n",
    "    idx = max(0, idx-1)\n",
    "    show()\n",
    "\n",
    "btn_flower.on_click(lambda _: move_to(FLOWER_DIR))\n",
    "btn_non.on_click(lambda _: move_to(NON_DIR))\n",
    "btn_skip.on_click(skip)\n",
    "btn_back.on_click(back)\n",
    "\n",
    "display(widgets.HBox([btn_back, btn_skip, btn_flower, btn_non]), status, img_out)\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a026aa35-1c88-46c2-9dda-21613e7ad724",
   "metadata": {},
   "source": [
    "# downloading random images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe2a32f4-ebc6-4c79-9778-e37674a3829c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Copied 150 images from inat_images_texas_bull_nettle\n",
      "âœ… Copied 150 images from inat_images_spurge_nettle\n",
      "\n",
      "ðŸ“¸ Total images in random_300_flowers: 300\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# --- 1. Configure your folders ---\n",
    "source_folder1 = \"inat_images_texas_bull_nettle\"   # First source folder\n",
    "source_folder2 = \"inat_images_spurge_nettle\"       # Second source folder\n",
    "destination_folder = \"random_300_flowers\"          # Destination folder\n",
    "num_images_per_folder = 150                        # How many to copy from each\n",
    "\n",
    "# --- 2. Make sure destination folder exists ---\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# --- 3. Helper function to randomly copy files ---\n",
    "def copy_random_images(source, dest, n):\n",
    "    all_images = [f for f in os.listdir(source)\n",
    "                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if not all_images:\n",
    "        print(f\"âš ï¸ No images found in {source}\")\n",
    "        return\n",
    "    \n",
    "    selected = random.sample(all_images, min(n, len(all_images)))\n",
    "    for img in selected:\n",
    "        src_path = os.path.join(source, img)\n",
    "        dst_path = os.path.join(dest, f\"{os.path.basename(source)}_{img}\")  # avoid overwriting\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    print(f\"âœ… Copied {len(selected)} images from {source}\")\n",
    "\n",
    "# --- 4. Copy from both folders ---\n",
    "copy_random_images(source_folder1, destination_folder, num_images_per_folder)\n",
    "copy_random_images(source_folder2, destination_folder, num_images_per_folder)\n",
    "\n",
    "print(f\"\\nðŸ“¸ Total images in {destination_folder}: {len(os.listdir(destination_folder))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee889a1-dbdc-4bc2-aeb4-8fca04de9395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
